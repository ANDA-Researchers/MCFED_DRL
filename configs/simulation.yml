# Run mode
run_mode: "simulation"  # 'simulation' or 'train'

# Loggers
logger: "tensorboard"  # Logger to use for logging (e.g., 'wandb' or 'tensorboard')

# Simulation settings
num_rsu: 3  # Number of RSUs (Road Side Units)
num_vehicle: 90  # Total number of vehicles in the simulation
time_step_per_round: 60  # Duration of each round in time steps
num_rounds: 1  # Total number of rounds for the simulation
content_size: 4000000  # Size of content in bytes (4e6)
deadline: 1  # Deadline for content delivery in seconds
interruption: true  # Whether to allow interruptions or not

# Mobility settings
min_velocity: 5  # Minimum speed of vehicles
max_velocity: 10  # Maximum speed of vehicles
std_velocity: 2.5  # Standard deviation of vehicle speed

# Connection settings
rsu_coverage: 500  # Coverage area of each RSU in meters
rsu_capacity: 200  # Maximum capacity of RSUs
cloud_rate: 50000000  # Cloud connection rate (100e6)
fiber_rate: 100000000  # Fiber optic connection rate (150e6)
max_connections: 10  # Maximum simultaneous connections
connection_switch_delay: 0.03

# FL (Federated Learning) settings
num_clusters: 3  # Number of clusters in FL
num_local_epochs: 100  # Number of local training epochs
parallel_update: false  # Whether to use parallel updates or not
fl_hidden_dim: 128  # Hidden dimension for the neural network

# DRL (Deep Reinforcement Learning) settings
episodes: 200  # Number of episodes to run
device: "cuda"  # Device to use for training (e.g., 'cuda' or 'cpu')
train_every: 1 # Frequency of training the agent
batch_size: 128  # Size of training batches
gamma: 0.99  # Discount factor for future rewards
lr: 0.00001  # Learning rate
capacity: 1800000  # Capacity for training
hidden_dim: 128  # Hidden dimension for the neural network
target_update: 1000   # Frequency of target network updates
training_steps: 3000 # Total training steps per episode
epsilon_decay: 0.99999  # Decay rate for exploration
epsilon_min: 0.02 # Minimum value for epsilon
alpha1: 1000  # avg delay
alpha2: 100 # hit ratio
alpha3: 30  # success ratio
alpha4: 10 # penalty
baseline: 200 # Baseline value for the reward
tau: 0.001  # Tau parameter for soft update
